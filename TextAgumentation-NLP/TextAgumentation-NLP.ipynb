{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometime ML algorithms need more data to train and getting more data is time and money consuming..\n",
    "#there are three ways to deal with this\n",
    "# 1) randomly remove tokens\n",
    "# 2) attach parts of speech tags\n",
    "# 3) replace named entities with their categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"I visited this place on Valentine's day in the evening. \n",
    "We had to wait for around 15 minutes to get a table here. We utilised that time in getting pictures ;) \n",
    "This place had a very chill vibe with loud music in the background. \n",
    "Live telecast of a cricket match was also going on. It was a little difficult to hold a conversation with someone.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) randomly remove tokens-step a) tokenize step b)find number of tokens \n",
    "# step c)set % of tokens to keep step d) randomly omit the words to generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "tokens=[t.text for t in doc]\n",
    "tokens\n",
    "l=len(tokens)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "text_agument1=[]\n",
    "#let's get the 3 versions of the text with random removal of tokens..let's say we want to randomly remove 20% tokens\n",
    "n=3\n",
    "# number of tokens to keep\n",
    "tokens_keep = round(0.8*l)\n",
    "print(tokens_keep)\n",
    "\n",
    "for i in range(n):\n",
    "    rand_index=random.sample(range(l),tokens_keep) #randomly sample(generate) 59 numbers (80%) between 0:74 (# of tokens)\n",
    "    rand_index.sort()#sort them\n",
    "    tokens_new=[tokens[t] for t in rand_index] #each i generate random 59 tokens\n",
    "    text_agument1.append(' '.join(tokens_new))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visited this place Valentine day in the evening . \n",
      " We had to for around minutes to get a table here . utilised that in getting ;) \n",
      " This place had a chill vibe with loud music in the background . \n",
      " Live telecast of cricket match was going on . It was little difficult to a conversation someone\n",
      "\n",
      "I this place on Valentine 's day in the evening . \n",
      " We had wait for around minutes get a table here . that in getting pictures ;) \n",
      " This place had a chill vibe loud music in background . \n",
      " telecast of a cricket match was also going on It was a little hold a with someone .\n",
      "\n",
      "I visited this Valentine 's day in the evening . \n",
      " We had to wait for around 15 minutes to a table here . We utilised time in getting pictures \n",
      " This place had a very chill vibe with loud in the background . \n",
      " Live of a cricket was also going . was difficult hold conversation with .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in text_agument1:\n",
    "    print(text+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Concatenate POS TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I_PRON', 'visited_VERB', 'this_DET', 'place_NOUN', 'on_ADP', 'Valentine_PROPN', \"'s_PART\", 'day_NOUN', 'in_ADP', 'the_DET', 'evening_NOUN', '._PUNCT', '\\n_SPACE', 'We_PRON', 'had_VERB', 'to_PART', 'wait_VERB', 'for_ADP', 'around_ADP', '15_NUM', 'minutes_NOUN', 'to_PART', 'get_VERB', 'a_DET', 'table_NOUN', 'here_ADV', '._PUNCT', 'We_PRON', 'utilised_VERB', 'that_DET', 'time_NOUN', 'in_ADP', 'getting_VERB', 'pictures_NOUN', ';)_PUNCT', '\\n_SPACE', 'This_DET', 'place_NOUN', 'had_VERB', 'a_DET', 'very_ADV', 'chill_ADJ', 'vibe_NOUN', 'with_ADP', 'loud_ADJ', 'music_NOUN', 'in_ADP', 'the_DET', 'background_NOUN', '._PUNCT', '\\n_SPACE', 'Live_VERB', 'telecast_NOUN', 'of_ADP', 'a_DET', 'cricket_NOUN', 'match_NOUN', 'was_VERB', 'also_ADV', 'going_VERB', 'on_PART', '._PUNCT', 'It_PRON', 'was_VERB', 'a_DET', 'little_ADJ', 'difficult_ADJ', 'to_PART', 'hold_VERB', 'a_DET', 'conversation_NOUN', 'with_ADP', 'someone_NOUN', '._PUNCT']\n"
     ]
    }
   ],
   "source": [
    "text_agument2=[]\n",
    "for tok in doc:\n",
    "    text_agument2.append(tok.text+ '_' +tok.pos_)\n",
    "print(text_agument2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_PRON visited_VERB this_DET place_NOUN on_ADP Valentine_PROPN 's_PART day_NOUN in_ADP the_DET evening_NOUN ._PUNCT \n",
      "_SPACE We_PRON had_VERB to_PART wait_VERB for_ADP around_ADP 15_NUM minutes_NOUN to_PART get_VERB a_DET table_NOUN here_ADV ._PUNCT We_PRON utilised_VERB that_DET time_NOUN in_ADP getting_VERB pictures_NOUN ;)_PUNCT \n",
      "_SPACE This_DET place_NOUN had_VERB a_DET very_ADV chill_ADJ vibe_NOUN with_ADP loud_ADJ music_NOUN in_ADP the_DET background_NOUN ._PUNCT \n",
      "_SPACE Live_VERB telecast_NOUN of_ADP a_DET cricket_NOUN match_NOUN was_VERB also_ADV going_VERB on_PART ._PUNCT It_PRON was_VERB a_DET little_ADJ difficult_ADJ to_PART hold_VERB a_DET conversation_NOUN with_ADP someone_NOUN ._PUNCT\n"
     ]
    }
   ],
   "source": [
    "text_agument2=' '.join(text_agument2)\n",
    "\n",
    "print(text_agument2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Replace named entities by there categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I visited this place on PERSON's day in the evening. \n",
      "We had to wait for TIME to get a table here. We utilised that time in getting pictures ;) \n",
      "This place had a very chill vibe with loud music in the background. \n",
      "Live telecast of a cricket match was also going on. It was a little difficult to hold a conversation with someone.\n"
     ]
    }
   ],
   "source": [
    "text_agument3=sample_text\n",
    "\n",
    "for ent in doc.ents:\n",
    "    text_agument3=re.sub(ent.text,ent.label_,text_agument3)\n",
    "print(text_agument3)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
