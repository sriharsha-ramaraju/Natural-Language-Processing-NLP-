{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      "text     2225 non-null object\n",
      "label    2225 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n",
      "           index  label\n",
      "0          sport    511\n",
      "1       business    510\n",
      "2       politics    417\n",
      "3           tech    401\n",
      "4  entertainment    386\n",
      "------------\n",
      "sport : 22.97 %\n",
      "business : 22.92 %\n",
      "politics : 18.74 %\n",
      "tech : 18.02 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    511\n",
       "0    510\n",
       "2    417\n",
       "4    401\n",
       "1    386\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bbc=pd.read_csv('bbc_news_mixed.csv')\n",
    "bbc.info() #\n",
    "bbc.label.value_counts() #gives how many observastions/articles are present per class label\n",
    "#looking at these value_counts, there is no class imbalance..more or less every class has similar number of obs\n",
    "bbc_shp=bbc.shape[0]\n",
    "label_val=bbc.label.value_counts().reset_index()\n",
    "print(label_val)\n",
    "print('------------')\n",
    "\n",
    "for lab in range(4):\n",
    "    print(label_val['index'][lab], ':' ,round(label_val['label'][lab]/bbc_shp*100,2),'%')\n",
    "    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labenc=LabelEncoder()\n",
    "bbc.label=labenc.fit_transform(bbc.label)#transforms text labels to numericals\n",
    "bbc.label.value_counts()#3-sport 0-business 2-politics 4-tech 1-entertainment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will be implementig GloVe embeddings one of the embedded feature extraction methods for NLP.  Word2Vec is a predictive \n",
    "model that predicts context given a word (or given a context predicts word). \n",
    "\n",
    "Glove also operates on the similar lines but it constructs the co-coccurance matrix (words x context) that counts how frequently a word appears in a context. This large matrix can be transformed into lower dimensions\n",
    "\n",
    "In word2vec, skip-gram models try to capture co-occurrence one window at a time.\n",
    "\n",
    "In Glove it tries to capture the counts of overall statistics how often it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('glove.6B.300d.txt',sep=\" \", quoting=3, header=None, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>0.046560</td>\n",
       "      <td>0.213180</td>\n",
       "      <td>-0.007436</td>\n",
       "      <td>-0.458540</td>\n",
       "      <td>-0.035639</td>\n",
       "      <td>0.236430</td>\n",
       "      <td>-0.288360</td>\n",
       "      <td>0.215210</td>\n",
       "      <td>-0.134860</td>\n",
       "      <td>-1.6413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013064</td>\n",
       "      <td>-0.296860</td>\n",
       "      <td>-0.079913</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.285060</td>\n",
       "      <td>-0.087461</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>-0.209890</td>\n",
       "      <td>0.053913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>-0.255390</td>\n",
       "      <td>-0.257230</td>\n",
       "      <td>0.131690</td>\n",
       "      <td>-0.042688</td>\n",
       "      <td>0.218170</td>\n",
       "      <td>-0.022702</td>\n",
       "      <td>-0.178540</td>\n",
       "      <td>0.107560</td>\n",
       "      <td>0.058936</td>\n",
       "      <td>-1.3854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>-0.014359</td>\n",
       "      <td>-0.073794</td>\n",
       "      <td>0.221760</td>\n",
       "      <td>0.146520</td>\n",
       "      <td>0.566860</td>\n",
       "      <td>0.053307</td>\n",
       "      <td>-0.232900</td>\n",
       "      <td>-0.122260</td>\n",
       "      <td>0.354990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>-0.125590</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>0.103060</td>\n",
       "      <td>-0.101230</td>\n",
       "      <td>0.098128</td>\n",
       "      <td>0.136270</td>\n",
       "      <td>-0.107210</td>\n",
       "      <td>0.236970</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>-1.6785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060148</td>\n",
       "      <td>-0.156190</td>\n",
       "      <td>-0.119490</td>\n",
       "      <td>0.234450</td>\n",
       "      <td>0.081367</td>\n",
       "      <td>0.246180</td>\n",
       "      <td>-0.152420</td>\n",
       "      <td>-0.342240</td>\n",
       "      <td>-0.022394</td>\n",
       "      <td>0.136840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>of</td>\n",
       "      <td>-0.076947</td>\n",
       "      <td>-0.021211</td>\n",
       "      <td>0.212710</td>\n",
       "      <td>-0.722320</td>\n",
       "      <td>-0.139880</td>\n",
       "      <td>-0.122340</td>\n",
       "      <td>-0.175210</td>\n",
       "      <td>0.121370</td>\n",
       "      <td>-0.070866</td>\n",
       "      <td>-1.5721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366730</td>\n",
       "      <td>-0.386030</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.015747</td>\n",
       "      <td>0.340360</td>\n",
       "      <td>0.478410</td>\n",
       "      <td>0.068617</td>\n",
       "      <td>0.183510</td>\n",
       "      <td>-0.291830</td>\n",
       "      <td>-0.046533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>to</td>\n",
       "      <td>-0.257560</td>\n",
       "      <td>-0.057132</td>\n",
       "      <td>-0.671900</td>\n",
       "      <td>-0.380820</td>\n",
       "      <td>-0.364210</td>\n",
       "      <td>-0.082155</td>\n",
       "      <td>-0.010955</td>\n",
       "      <td>-0.082047</td>\n",
       "      <td>0.460560</td>\n",
       "      <td>-1.8477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012806</td>\n",
       "      <td>-0.597070</td>\n",
       "      <td>0.317340</td>\n",
       "      <td>-0.252670</td>\n",
       "      <td>0.543840</td>\n",
       "      <td>0.063007</td>\n",
       "      <td>-0.049795</td>\n",
       "      <td>-0.160430</td>\n",
       "      <td>0.046744</td>\n",
       "      <td>-0.070621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7    \\\n",
       "0                                                                           \n",
       "the  0.046560  0.213180 -0.007436 -0.458540 -0.035639  0.236430 -0.288360   \n",
       ",   -0.255390 -0.257230  0.131690 -0.042688  0.218170 -0.022702 -0.178540   \n",
       ".   -0.125590  0.013630  0.103060 -0.101230  0.098128  0.136270 -0.107210   \n",
       "of  -0.076947 -0.021211  0.212710 -0.722320 -0.139880 -0.122340 -0.175210   \n",
       "to  -0.257560 -0.057132 -0.671900 -0.380820 -0.364210 -0.082155 -0.010955   \n",
       "\n",
       "          8         9       10   ...       291       292       293       294  \\\n",
       "0                                ...                                           \n",
       "the  0.215210 -0.134860 -1.6413  ... -0.013064 -0.296860 -0.079913  0.195000   \n",
       ",    0.107560  0.058936 -1.3854  ...  0.075968 -0.014359 -0.073794  0.221760   \n",
       ".    0.236970  0.328700 -1.6785  ...  0.060148 -0.156190 -0.119490  0.234450   \n",
       "of   0.121370 -0.070866 -1.5721  ... -0.366730 -0.386030  0.302900  0.015747   \n",
       "to  -0.082047  0.460560 -1.8477  ... -0.012806 -0.597070  0.317340 -0.252670   \n",
       "\n",
       "          295       296       297       298       299       300  \n",
       "0                                                                \n",
       "the  0.031549  0.285060 -0.087461  0.009061 -0.209890  0.053913  \n",
       ",    0.146520  0.566860  0.053307 -0.232900 -0.122260  0.354990  \n",
       ".    0.081367  0.246180 -0.152420 -0.342240 -0.022394  0.136840  \n",
       "of   0.340360  0.478410  0.068617  0.183510 -0.291830 -0.046533  \n",
       "to   0.543840  0.063007 -0.049795 -0.160430  0.046744 -0.070621  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#each word has got a 300 dimmension vector..creating dictionary style might be better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of vector representation of 'cake': 300\n"
     ]
    }
   ],
   "source": [
    "glove={key:val.values for key,val in df.T.items()}\n",
    "\n",
    "print('Shape of vector representation of \\'cake\\':', len(glove['cake']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
